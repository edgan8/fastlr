{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Xs, theta):\n",
    "    z = np.inner(Xs,theta)\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(X, y, theta):\n",
    "    z = np.dot(X,theta)\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    grd = np.dot(X.T, h-y)/y.shape[0]\n",
    "    return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, ndims, lr=.1):\n",
    "        self.eps = 1e-8\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.lr = lr\n",
    "        self.ndims = ndims\n",
    "        \n",
    "        self.mt = np.zeros(shape=(ndims))\n",
    "        self.vt = np.zeros(shape=(ndims))\n",
    "        self.theta = np.zeros(shape=(ndims))\n",
    "        self.t = 1\n",
    "        self.b1t = 1\n",
    "        self.b2t = 1\n",
    "\n",
    "    def step(self, grad):\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "        \n",
    "        self.mt *= b1\n",
    "        self.mt += (1-b1)*grad\n",
    "        self.vt *= b2\n",
    "        self.vt += (1-b2)*(grad*grad)\n",
    "        self.b1t *= b1\n",
    "        self.b2t *= b2\n",
    "        \n",
    "        at = (self.lr/math.sqrt(self.t))*np.sqrt(1-self.b2t)/(1-self.b1t)\n",
    "        self.theta -= at*self.mt/(np.sqrt(self.vt)+self.eps)\n",
    "        self.t += 1\n",
    "        return self.theta\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Actor Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class AdamParameterServer(object):\n",
    "    def __init__(self, dim, lr):\n",
    "        self.opt = AdamOptimizer(dim, lr=lr)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.opt.get_params()\n",
    "\n",
    "    def update_params(self, grad):\n",
    "        self.opt.step(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def gradient_worker(ps, X, y, batch_size):\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    start_idx = 0\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        X_b = X[start_idx:start_idx+batch_size]\n",
    "        y_b = y[start_idx:start_idx+batch_size]\n",
    "        cur_theta = ray.get(ps.get_params.remote())\n",
    "        cur_grad = calc_grad(X_b, y_b, cur_theta)\n",
    "        ps.update_params.remote(cur_grad)\n",
    "\n",
    "        start_idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_remote(X, y, num_processes, batch_size):\n",
    "    X_parts = np.array_split(X, num_processes)\n",
    "    y_parts = np.array_split(y, num_processes)\n",
    "    X_ids = [ray.put(X_part) for X_part in X_parts]\n",
    "    y_ids = [ray.put(y_part) for y_part in y_parts]\n",
    "    \n",
    "    ps = AdamParameterServer.remote(dim=X.shape[1], lr=.1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    workers = [\n",
    "        gradient_worker.remote(ps, X_ids[i], y_ids[i], batch_size)\n",
    "        for i in range(num_processes)\n",
    "    ]\n",
    "    worker_res = ray.get(workers)\n",
    "    end_time = time.time()\n",
    "    print(\"Elapsed Time: {}\".format(end_time - start_time))\n",
    "    return ray.get(ps.get_params.remote())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-09 00:36:42,148\tINFO resource_spec.py:205 -- Starting Ray with 21.68 GiB memory available for workers and up to 10.85 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.138.15.252',\n",
       " 'redis_address': '10.138.15.252:30047',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-09_00-36-42_146872_3957/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-09_00-36-42_146872_3957/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-11-09_00-36-42_146872_3957'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 1.716245174407959\n"
     ]
    }
   ],
   "source": [
    "theta = train_remote(Xc, y, num_processes=4, batch_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.45167819919278257\n"
     ]
    }
   ],
   "source": [
    "yh = predict(Xc, opt.get_params())\n",
    "score = sklearn.metrics.log_loss(y, yh)\n",
    "print(\"Log Loss: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.timeline(\"out.timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def calc_gradient(X, y, theta, start_idx, end_idx):\n",
    "    X = X[start_idx:end_idx]\n",
    "    y = y[start_idx:end_idx]\n",
    "    \n",
    "    z = np.dot(X,theta)\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    grd = np.dot(X.T, h-y)/y.shape[0]\n",
    "    return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedLR:\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_processes=8,\n",
    "    ):\n",
    "        self.eps = 1e-8\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.num_processes = num_processes\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        X, y,\n",
    "        lr, batch_size, num_epochs=1\n",
    "    ):\n",
    "        ndims = X.shape[1]\n",
    "        X_parts = np.array_split(X, self.num_processes)\n",
    "        y_parts = np.array_split(y, self.num_processes)\n",
    "        X_ids = [ray.put(X_part) for X_part in X_parts]\n",
    "        y_ids = [ray.put(y_part) for y_part in y_parts]\n",
    "        num_batches = int(math.ceil(X.shape[0] / (self.num_processes*batch_size)))\n",
    "        \n",
    "        t1 = time.time()\n",
    "        theta = np.zeros(shape=(ndims))\n",
    "        mt = np.zeros(shape=(ndims))\n",
    "        vt = np.zeros(shape=(ndims))\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "        eps = self.eps\n",
    "        b1t = b1\n",
    "        b2t = b2\n",
    "\n",
    "        start_idx = 0\n",
    "        t = 1\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            for batch_idx in tqdm(range(num_batches)):\n",
    "                theta_id = ray.put(theta)\n",
    "                grads = [\n",
    "                    calc_gradient.remote(\n",
    "                        X_ids[i], y_ids[i], theta_id,\n",
    "                        start_idx = batch_idx*batch_size,\n",
    "                        end_idx = (batch_idx+1)*batch_size\n",
    "                    ) \n",
    "                    for i in range(self.num_processes)\n",
    "                ]\n",
    "                grad_values = ray.get(grads)\n",
    "                cur_grad = np.mean(grad_values, axis=0)\n",
    "\n",
    "                mt *= b1\n",
    "                mt += (1-b1)*cur_grad\n",
    "                vt *= b2\n",
    "                vt += (1-b2)*(cur_grad*cur_grad)\n",
    "                at = (lr/math.sqrt(t))*np.sqrt(1-b2t)/(1-b1t)\n",
    "                theta -= at*mt/(np.sqrt(vt)+eps)\n",
    "\n",
    "                start_idx += batch_size\n",
    "                b1t *= b1\n",
    "                b2t *= b2\n",
    "                t += 1\n",
    "\n",
    "        t2 = time.time()\n",
    "        print(\"Total Time: {}\".format(t2-t1))\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class GradientWorker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, y\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def calc_grad(\n",
    "        self,\n",
    "        theta,\n",
    "        start_idx,\n",
    "        end_idx\n",
    "    ):\n",
    "        X = self.X[start_idx:end_idx]\n",
    "        y = self.y[start_idx:end_idx]\n",
    "        z = np.dot(X,theta)\n",
    "        h = 1/(1+np.exp(-z))\n",
    "        grd = np.dot(X.T, h-y)/y.shape[0]\n",
    "        return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedActorLR:\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_processes=8,\n",
    "    ):\n",
    "        self.eps = 1e-8\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.num_processes = num_processes\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        X, y,\n",
    "        lr, batch_size, num_epochs=1\n",
    "    ):\n",
    "        ndims = X.shape[1]\n",
    "        X_parts = np.array_split(X, self.num_processes)\n",
    "        y_parts = np.array_split(y, self.num_processes)\n",
    "        X_ids = [ray.put(X_part) for X_part in X_parts]\n",
    "        y_ids = [ray.put(y_part) for y_part in y_parts]\n",
    "        num_batches = int(math.ceil(X.shape[0] / (self.num_processes*batch_size)))\n",
    "        workers = [GradientWorker.remote(X_ids[i], y_ids[i]) for i in range(self.num_processes)]\n",
    "        \n",
    "        t1 = time.time()\n",
    "        theta = np.zeros(shape=(ndims))\n",
    "        mt = np.zeros(shape=(ndims))\n",
    "        vt = np.zeros(shape=(ndims))\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "        eps = self.eps\n",
    "        b1t = b1\n",
    "        b2t = b2\n",
    "\n",
    "        start_idx = 0\n",
    "        t = 1\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            for batch_idx in tqdm(range(num_batches)):\n",
    "                theta_id = ray.put(theta)\n",
    "                grads = [\n",
    "                    cur_worker.calc_grad.remote(\n",
    "                        theta_id,\n",
    "                        start_idx = batch_idx*batch_size,\n",
    "                        end_idx = (batch_idx+1)*batch_size\n",
    "                    ) \n",
    "                    for cur_worker in workers\n",
    "                ]\n",
    "                grad_values = ray.get(grads)\n",
    "                cur_grad = np.mean(grad_values, axis=0)\n",
    "\n",
    "                mt *= b1\n",
    "                mt += (1-b1)*cur_grad\n",
    "                vt *= b2\n",
    "                vt += (1-b2)*(cur_grad*cur_grad)\n",
    "                at = (lr/math.sqrt(t))*np.sqrt(1-b2t)/(1-b1t)\n",
    "                theta -= at*mt/(np.sqrt(vt)+eps)\n",
    "\n",
    "                start_idx += batch_size\n",
    "                b1t *= b1\n",
    "                b2t *= b2\n",
    "                t += 1\n",
    "\n",
    "        t2 = time.time()\n",
    "        print(\"Total Time: {}\".format(t2-t1))\n",
    "        return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class AdamWorker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ndims\n",
    "    ):        \n",
    "        self.eps = 1e-8\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.mt = np.zeros(shape=(ndims))\n",
    "        self.vt = np.zeros(shape=(ndims))\n",
    "        self.t = 1\n",
    "\n",
    "    def calc_grad(\n",
    "        self,\n",
    "        X, y,\n",
    "        theta\n",
    "    ):\n",
    "        z = np.dot(X,theta)\n",
    "        h = 1/(1+np.exp(-z))\n",
    "        grd = np.dot(X.T, h-y)/y.shape[0]\n",
    "        return grd\n",
    "\n",
    "    def run_epoch(\n",
    "        self,\n",
    "        X, y,\n",
    "        theta,\n",
    "        lr, batch_size,\n",
    "    ):\n",
    "        b1 = self.b1\n",
    "        b2 = self.b2\n",
    "        eps = self.eps\n",
    "\n",
    "        start_idx = 0\n",
    "        num_batches = int(math.ceil(X.shape[0] / batch_size))\n",
    "        for batch_idx in range(num_batches):\n",
    "            cur_grad = self.calc_grad(\n",
    "                X=X[start_idx:start_idx+batch_size],\n",
    "                y=y[start_idx:start_idx+batch_size],\n",
    "                theta=theta,\n",
    "            )\n",
    "            self.mt *= b1\n",
    "            self.mt += (1-b1)*cur_grad\n",
    "            self.vt *= b2\n",
    "            self.vt += (1-b2)*(cur_grad*cur_grad)\n",
    "            b1t = math.pow(b1, self.t)\n",
    "            b2t = math.pow(b2, self.t)\n",
    "            at = (lr/math.sqrt(self.t))*np.sqrt(1-b2t)/(1-b1t)\n",
    "            theta -= at*self.mt/(np.sqrt(self.vt)+eps)\n",
    "\n",
    "            start_idx += batch_size\n",
    "            self.t += 1\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedAdamActorLR:\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_processes=4,\n",
    "    ):\n",
    "        self.num_processes = num_processes\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        X, y,\n",
    "        lr, batch_size, num_epochs=1\n",
    "    ):\n",
    "        ndims = X.shape[1]\n",
    "        X_parts = np.array_split(X, self.num_processes)\n",
    "        y_parts = np.array_split(y, self.num_processes)\n",
    "        X_ids = [ray.put(X_part) for X_part in X_parts]\n",
    "        y_ids = [ray.put(y_part) for y_part in y_parts]\n",
    "        num_batches = int(math.ceil(X.shape[0] / (self.num_processes*batch_size)))\n",
    "        workers = [AdamWorker.remote(ndims) for i in range(self.num_processes)]\n",
    "        theta = np.zeros(shape=(ndims))\n",
    "        \n",
    "        t1 = time.time()\n",
    "        start_idx = 0\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            theta_ids = [\n",
    "                workers[i].run_epoch.remote(\n",
    "                    X_ids[i], y_ids[i],\n",
    "                    theta, lr, batch_size\n",
    "                )\n",
    "                for i in range(self.num_processes)\n",
    "            ]\n",
    "            thetas = ray.get(theta_ids)\n",
    "            theta = np.mean(thetas, axis=0)\n",
    "        t2 = time.time()\n",
    "        print(\"Total Time: {}\".format(t2-t1))\n",
    "        return thetas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"~/data/avazu/train_10M.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"click\"\n",
    "CAT_COLS = [\n",
    "    \"C1\", \"banner_pos\", \n",
    "    \"site_category\", \"app_category\", \n",
    "    \"device_type\", \"device_conn_type\",\n",
    "]\n",
    "df_enc = pd.get_dummies(df[CAT_COLS], columns=CAT_COLS)\n",
    "df_final = pd.concat([\n",
    "    df[target], df_enc\n",
    "], axis=1)\n",
    "\n",
    "nrows = 4_000_000\n",
    "np.random.seed(0)\n",
    "r_order = np.random.permutation(nrows)\n",
    "Xs = df_enc.values[:nrows][r_order]\n",
    "y = df[target].values[:nrows][r_order]\n",
    "\n",
    "Xc = np.concatenate([\n",
    "    np.repeat(1, repeats=Xs.shape[0]).reshape(-1,1),\n",
    "    Xs\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 116.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 1.7173857688903809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(Xc)\n",
    "start_idx = 0\n",
    "t = 1\n",
    "lr = 0.1\n",
    "start_time = time.time()\n",
    "opt = AdamOptimizer(Xc.shape[1], lr=lr)\n",
    "batch_size = 20000\n",
    "for batch_idx in tqdm(range(n_rows // batch_size)):\n",
    "    X_b = Xc[start_idx:start_idx+batch_size]\n",
    "    y_b = y[start_idx:start_idx+batch_size]\n",
    "    cur_grad = calc_grad(X_b, y_b, opt.get_params())\n",
    "    opt.step(cur_grad)\n",
    "    \n",
    "    start_idx += batch_size\n",
    "end_time = time.time()\n",
    "print(\"Total Time: {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.45167819919278257\n"
     ]
    }
   ],
   "source": [
    "yh = predict(Xc, opt.get_params())\n",
    "score = sklearn.metrics.log_loss(y, yh)\n",
    "print(\"Log Loss: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 00:47:49,856\tINFO resource_spec.py:205 -- Starting Ray with 23.44 GiB memory available for workers and up to 11.74 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.138.15.252',\n",
       " 'redis_address': '10.138.15.252:48027',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-08_00-47-49_854898_7223/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-08_00-47-49_854898_7223/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-11-08_00-47-49_854898_7223'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.99it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 26.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 3.707850217819214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = DistributedLR(\n",
    "    num_processes=4\n",
    ")\n",
    "theta = lr.train(\n",
    "    Xc, y, \n",
    "    lr=.1, \n",
    "    batch_size=20000, num_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 27.86it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 3.6107382774353027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = DistributedActorLR(\n",
    "    num_processes=4\n",
    ")\n",
    "theta = lr.train(\n",
    "    Xc, y, \n",
    "    lr=.1, \n",
    "    batch_size=20000, num_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 3.728069305419922\n"
     ]
    }
   ],
   "source": [
    "lr = DistributedAdamActorLR(\n",
    "    num_processes=4\n",
    ")\n",
    "theta = lr.train(\n",
    "    Xc, y, \n",
    "    lr=.1, \n",
    "    batch_size=1024, num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.timeline(\"timeline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.45167728815928004\n"
     ]
    }
   ],
   "source": [
    "yh = predict(Xc, theta)\n",
    "score = sklearn.metrics.log_loss(y, yh)\n",
    "print(\"Log Loss: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
